{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/neelnanda-io/TransformerLens/blob/main/demos/LLaMA.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yi in TransformerLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup (skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running as a Jupyter notebook - intended for development only!\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6837/572068249.py:21: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "  ipython.magic(\"load_ext autoreload\")\n",
      "/tmp/ipykernel_6837/572068249.py:22: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "  ipython.magic(\"autoreload 2\")\n"
     ]
    }
   ],
   "source": [
    "# Janky code to do different setup when run in a Colab notebook vs VSCode\n",
    "DEVELOPMENT_MODE = False\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"Running as a Colab notebook\")\n",
    "    %pip install git+https://github.com/neelnanda-io/TransformerLens.git``\n",
    "    %pip install circuitsvis\n",
    "    \n",
    "    # PySvelte is an unmaintained visualization library, use it as a backup if circuitsvis isn't working\n",
    "    # # Install another version of node that makes PySvelte work way faster\n",
    "    # !curl -fsSL https://deb.nodesource.com/setup_16.x | sudo -E bash -; sudo apt-get install -y nodejs\n",
    "    # %pip install git+https://github.com/neelnanda-io/PySvelte.git\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    print(\"Running as a Jupyter notebook - intended for development only!\")\n",
    "    from IPython import get_ipython\n",
    "\n",
    "    ipython = get_ipython()\n",
    "    # Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n",
    "    ipython.magic(\"load_ext autoreload\")\n",
    "    ipython.magic(\"autoreload 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using renderer: colab\n"
     ]
    }
   ],
   "source": [
    "# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n",
    "import plotly.io as pio\n",
    "if IN_COLAB or not DEVELOPMENT_MODE:\n",
    "    pio.renderers.default = \"colab\"\n",
    "else:\n",
    "    pio.renderers.default = \"notebook_connected\"\n",
    "print(f\"Using renderer: {pio.renderers.default}\")\n",
    "\n",
    "import circuitsvis as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import stuff\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import einops\n",
    "from fancy_einsum import einsum\n",
    "import tqdm.auto as tqdm\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from pathlib import Path\n",
    "import plotly.express as px\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from typing import List, Union, Optional\n",
    "from jaxtyping import Float, Int\n",
    "from functools import partial\n",
    "import copy\n",
    "\n",
    "import itertools\n",
    "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
    "import dataclasses\n",
    "import datasets\n",
    "from IPython.display import HTML\n",
    "# import circuitsvis as cv\n",
    "\n",
    "import transformer_lens\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens.hook_points import (\n",
    "    HookedRootModule,\n",
    "    HookPoint,\n",
    ")  # Hooking utilities\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "def imshow(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
    "    px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=0.0, color_continuous_scale=\"RdBu\", labels={\"x\":xaxis, \"y\":yaxis}, **kwargs).show(renderer)\n",
    "\n",
    "def line(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
    "    px.line(utils.to_numpy(tensor), labels={\"x\":xaxis, \"y\":yaxis}, **kwargs).show(renderer)\n",
    "\n",
    "def scatter(x, y, xaxis=\"\", yaxis=\"\", caxis=\"\", renderer=None, **kwargs):\n",
    "    x = utils.to_numpy(x)\n",
    "    y = utils.to_numpy(y)\n",
    "    px.scatter(y=y, x=x, labels={\"x\":xaxis, \"y\":yaxis, \"color\":caxis}, **kwargs).show(renderer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5708f232f4f5428faa7cdb910e1f715f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/320 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a911d44d318466aaa16a6a058e025dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/1.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e36f111a77ee44aba4d51060609e9505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/3.56M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f7c6db4532d4bb790757363f1dc4250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/605 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bedd7cf3fee449da9e32a8ad703b3b72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d2a979df8b441dfab5605826f3fa396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "503b042cee974395899baed022b72436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f71361a4c32140f5945fe8fa3b522e37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.18G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f0fddae796d441e9cbe78e1cab2cb1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4c34780d52a4ec1ad47c31dadfd8e7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import os\n",
    "\n",
    "MODEL_PATH='01-ai/Yi-6B'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "hf_model = AutoModelForCausalLM.from_pretrained(MODEL_PATH, low_cpu_mem_usage=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CFG_DICT\n",
      "{'d_model': 4096, 'd_head': 128, 'n_heads': 32, 'd_mlp': 11008, 'n_layers': 32, 'n_ctx': 4096, 'eps': 1e-05, 'd_vocab': 64000, 'act_fn': 'silu', 'normalization_type': 'RMS', 'positional_embedding_type': 'rotary', 'rotary_dim': 128, 'final_rms': True, 'gated_mlp': True}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e244ab6c34fa4f27aa165866e19310f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for HookedTransformer:\n\tsize mismatch for blocks.0.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.0.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.1.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.1.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.2.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.2.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.3.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.3.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.4.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.4.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.5.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.5.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.6.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.6.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.7.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.7.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.8.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.8.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.9.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.9.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.10.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.10.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.11.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.11.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.12.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.12.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.13.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.13.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.14.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.14.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.15.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.15.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.16.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.16.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.17.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.17.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.18.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.18.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.19.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.19.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.20.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.20.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.21.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.21.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.22.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.22.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.23.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.23.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.24.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.24.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.25.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.25.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.26.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.26.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.27.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.27.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.28.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.28.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.29.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.29.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.30.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.30.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.31.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.31.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Loading on CPU is cheapest memory wise in transformer_lens \u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mHookedTransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold_ln\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenter_writing_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenter_unembed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/TransformerLens/transformer_lens/HookedTransformer.py:1294\u001b[0m, in \u001b[0;36mHookedTransformer.from_pretrained\u001b[0;34m(cls, model_name, fold_ln, center_writing_weights, center_unembed, refactor_factored_attn_matrices, checkpoint_index, checkpoint_value, hf_model, device, n_devices, tokenizer, move_to_device, fold_value_biases, default_prepend_bos, default_padding_side, dtype, **from_pretrained_kwargs)\u001b[0m\n\u001b[1;32m   1286\u001b[0m \u001b[38;5;66;03m# Create the HookedTransformer object\u001b[39;00m\n\u001b[1;32m   1287\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\n\u001b[1;32m   1288\u001b[0m     cfg,\n\u001b[1;32m   1289\u001b[0m     tokenizer,\n\u001b[1;32m   1290\u001b[0m     move_to_device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1291\u001b[0m     default_padding_side\u001b[38;5;241m=\u001b[39mdefault_padding_side,\n\u001b[1;32m   1292\u001b[0m )\n\u001b[0;32m-> 1294\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_and_process_state_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfold_ln\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfold_ln\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcenter_writing_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcenter_writing_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcenter_unembed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcenter_unembed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfold_value_biases\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfold_value_biases\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrefactor_factored_attn_matrices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefactor_factored_attn_matrices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1301\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m move_to_device:\n\u001b[1;32m   1304\u001b[0m     model\u001b[38;5;241m.\u001b[39mmove_model_modules_to_device()\n",
      "File \u001b[0;32m~/TransformerLens/transformer_lens/HookedTransformer.py:1444\u001b[0m, in \u001b[0;36mHookedTransformer.load_and_process_state_dict\u001b[0;34m(self, state_dict, fold_ln, center_writing_weights, center_unembed, fold_value_biases, refactor_factored_attn_matrices)\u001b[0m\n\u001b[1;32m   1442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m refactor_factored_attn_matrices:\n\u001b[1;32m   1443\u001b[0m     state_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefactor_factored_attn_matrices(state_dict)\n\u001b[0;32m-> 1444\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/transformer-lens-v47roMa8-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:2152\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2147\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2148\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2149\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2153\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for HookedTransformer:\n\tsize mismatch for blocks.0.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.0.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.1.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.1.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.2.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.2.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.3.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.3.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.4.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.4.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.5.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.5.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.6.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.6.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.7.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.7.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.8.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.8.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.9.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.9.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.10.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.10.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.11.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.11.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.12.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.12.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.13.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.13.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.14.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.14.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.15.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.15.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.16.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.16.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.17.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.17.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.18.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.18.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.19.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.19.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.20.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.20.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.21.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.21.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.22.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.22.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.23.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.23.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.24.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.24.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.25.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.25.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.26.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.26.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.27.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.27.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.28.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.28.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.29.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.29.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.30.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.30.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.31.attn.W_K: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128]).\n\tsize mismatch for blocks.31.attn.W_V: copying a param with shape torch.Size([32, 4096, 16]) from checkpoint, the shape in current model is torch.Size([32, 4096, 128])."
     ]
    }
   ],
   "source": [
    "# Loading on CPU is cheapest memory wise in transformer_lens \n",
    "\n",
    "model = HookedTransformer.from_pretrained(MODEL_PATH, device=\"cpu\", fold_ln=False, center_writing_weights=False, center_unembed=False, tokenizer=tokenizer)\n",
    "\n",
    "model = model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like Yi uses grouped query qttention, even for smaller model sizes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f03ec946e3b5caa7cc710a963f479e62a68fff56c790a7066e03c8b5c22adad9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
